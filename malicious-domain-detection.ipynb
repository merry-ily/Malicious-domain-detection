{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting tldextract\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/12/cf/d0ff82625e53bd245d6173ce6333d190abbfcd94e4c30e54b4e16b474216/tldextract-2.2.3-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 15.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tldextract) (2.8)\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tldextract) (2.22.0)\n",
      "Collecting requests-file>=1.4 (from tldextract)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (2019.9.11)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests-file>=1.4->tldextract) (1.15.0)\n",
      "Installing collected packages: requests-file, tldextract\n",
      "Successfully installed requests-file-1.5.1 tldextract-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "!pip install tldextract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress as ip\n",
    "from urllib.parse import urlparse\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "用于提取特征的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countdots(url):  \r\n",
    "    return url.count('.')\r\n",
    "\r\n",
    "def isip(uri):\r\n",
    "    try:\r\n",
    "        if ip.ip_address(uri):\r\n",
    "            return 1\r\n",
    "    except:\r\n",
    "        return 0\r\n",
    "\r\n",
    "def isPresentHyphen(url):\r\n",
    "    return url.count('-')\r\n",
    "\r\n",
    "def isPresentAt(url):\r\n",
    "    return url.count('@')\r\n",
    "\r\n",
    "def isPresentDSlash(url):\r\n",
    "    return url.count('//')\r\n",
    "\r\n",
    "def countSubDir(url):\r\n",
    "    return url.count('/')\r\n",
    "\r\n",
    "def get_ext(url):\r\n",
    "    \"\"\"Return the filename extension from url, or ''.\"\"\"  \r\n",
    "    root, ext = splitext(url)\r\n",
    "    return ext\r\n",
    "\r\n",
    "def countSubDomain(subdomain):\r\n",
    "    if not subdomain:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return len(subdomain.split('.'))\r\n",
    "\r\n",
    "def countQueries(query):\r\n",
    "    if not query:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return len(query.split('&'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeatures(url, label): \r\n",
    "     #2016's top most suspicious TLD and words\r\n",
    "    Suspicious_TLD=['zip','cricket','link','work','party','gq','kim','country','science','tk']\r\n",
    "    Suspicious_Domain=['luckytime.co.kr','mattfoll.eu.interia.pl','trafficholder.com','dl.baixaki.com.br','bembed.redtube.comr','tags.expo9.exponential.com','deepspacer.com','funad.co.kr','trafficconverter.biz']\r\n",
    "    #trend micro's top malicious domains \r\n",
    "    result = []\r\n",
    "    url = str(url)\r\n",
    "    \r\n",
    "    #add the url to feature set\r\n",
    "    result.append(url)\r\n",
    "    result.append(str(label))\r\n",
    "    \r\n",
    "    #parse the URL and extract the domain information\r\n",
    "    path = urlparse(url)\r\n",
    "    ext = tldextract.extract(url)\r\n",
    "    \r\n",
    "    #counting number of dots in subdomain    \r\n",
    "    result.append(countdots(ext.subdomain))\r\n",
    "    \r\n",
    "    #checking hyphen in domain   \r\n",
    "    result.append(isPresentHyphen(path.netloc))\r\n",
    "    \r\n",
    "    #length of URL    \r\n",
    "    result.append(len(url))\r\n",
    "    \r\n",
    "    #checking @ in the url    \r\n",
    "    result.append(isPresentAt(path.netloc))\r\n",
    "    \r\n",
    "    #checking presence of double slash    \r\n",
    "    result.append(isPresentDSlash(path.path))\r\n",
    "    \r\n",
    "    #Count number of subdir    \r\n",
    "    result.append(countSubDir(path.path))\r\n",
    "    \r\n",
    "    #number of sub domain    \r\n",
    "    result.append(countSubDomain(ext.subdomain))\r\n",
    "    \r\n",
    "    #length of domain name    \r\n",
    "    result.append(len(path.netloc))\r\n",
    "    \r\n",
    "    #count number of queries    \r\n",
    "    result.append(len(path.query))\r\n",
    "    \r\n",
    "    #Adding domain information\r\n",
    "    \r\n",
    "    #if IP address is being used as a URL     \r\n",
    "    result.append(isip(ext.domain))\r\n",
    "    \r\n",
    "    #presence of Suspicious_TLD\r\n",
    "    result.append(1 if ext.suffix in Suspicious_TLD else 0)\r\n",
    "    \r\n",
    "    #presence of suspicious domain\r\n",
    "    result.append(1 if '.'.join(ext[1:]) in Suspicious_Domain else 0 )\r\n",
    "\r\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 读取原始数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14157"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.txt')\r\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "目标数据集featureSet的各列名："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(columns=('url','label','no of dots','presence of hyphen','len of url','presence of at',\\\r\n",
    "    'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\r\n",
    "    'presence of suspicious domain'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "将各个特征写入目标数据集featureSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\r\n",
    "        features = getFeatures(data[\"url\"].loc[i], data['label'].loc[i])   \r\n",
    "        featureSet.loc[i] = features   \r\n",
    "        if i %1000 == 0:\r\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "将含有特征的数据集保存为trainData.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureSet\r\n",
    "featureSet.to_csv('trainData.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**决策树模型：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "从含有特征的数据文件中读取数据，x为输入的数据，y为输出的数据；\n",
    "输入的数据需要把url、label两列去掉，除此之外还有第一列的序号需要去除；\n",
    "输出的数据仅为label一列的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('trainData.txt')\r\n",
    "x = data.drop(['url','label'],axis=1).values\r\n",
    "x = np.delete(x,obj=0,axis=1)\r\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用train_test_split将0.3的数据集划分为测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 13, ...,  0,  0,  0],\n",
       "       [ 0,  0, 15, ...,  0,  0,  0],\n",
       "       [ 0,  0, 43, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0, 14, ...,  0,  0,  0],\n",
       "       [ 0,  0, 10, ...,  0,  0,  0],\n",
       "       [ 0,  0, 15, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y ,test_size=0.3)\r\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义训练集为决策树模型；\n",
    "使用.fit训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\r\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**模型评估：**\n",
    "使用.predict预测测试集的输出，用accuracy_score根据测试集输出和预测结果求准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9406779661017\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\r\n",
    "accuracy = 100.0 * accuracy_score(y_test, predictions)\r\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9177570093457944"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979674796747967"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9905136744373801\n"
     ]
    }
   ],
   "source": [
    "score_train = classifier.score(x_train,y_train)\r\n",
    "print(score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**随机森林：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\r\n",
    "random_forest.fit(x_train, y_train)\r\n",
    "acc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\r\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912900188323918"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\r\n",
    "y_pred = random_forest.predict(x_test)\r\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9288461538461539"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_url_features(url): \r\n",
    "     #2016's top most suspicious TLD and words\r\n",
    "    Suspicious_TLD=['zip','cricket','link','work','party','gq','kim','country','science','tk']\r\n",
    "    Suspicious_Domain=['luckytime.co.kr','mattfoll.eu.interia.pl','trafficholder.com','dl.baixaki.com.br','bembed.redtube.comr','tags.expo9.exponential.com','deepspacer.com','funad.co.kr','trafficconverter.biz']\r\n",
    "    \r\n",
    "    #trend micro's top malicious domains \r\n",
    "    url = str(url)\r\n",
    "        \r\n",
    "    #parse the URL and extract the domain information\r\n",
    "    path = urlparse(url)\r\n",
    "    ext = tldextract.extract(url)\r\n",
    "\r\n",
    "    return [countdots(ext.subdomain),isPresentHyphen(path.netloc), len(url), isPresentAt(path.netloc), isPresentDSlash(path.path), countSubDir(path.path),\\\r\n",
    "            countSubDomain(ext.subdomain), len(path.netloc), len(path.query), isip(ext.domain), 1 if ext.suffix in Suspicious_TLD else 0,\\\r\n",
    "            1 if '.'.join(ext[1:]) in Suspicious_Domain else 0]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def whether_good(test_url):\r\n",
    "    test_features=[]\r\n",
    "    test_features.append(get_url_features(test_url))\r\n",
    "    # print(test_features)\r\n",
    "    pre_random = random_forest.predict(test_features)\r\n",
    "    pre_tree = classifier.predict(test_features)\r\n",
    "    print('random forest',pre_random)\r\n",
    "    print('classify tree',pre_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest [0]\n",
      "classify tree [0]\n"
     ]
    }
   ],
   "source": [
    "test_url = 'zhihu.com'\r\n",
    "\r\n",
    "whether_good(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest [1]\n",
      "classify tree [1]\n"
     ]
    }
   ],
   "source": [
    "whether_good('destre45.com/p/f.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest [0]\n",
      "classify tree [0]\n"
     ]
    }
   ],
   "source": [
    "whether_good('baidu.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest [1]\n",
      "classify tree [1]\n"
     ]
    }
   ],
   "source": [
    "whether_good('www.archigate.it/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest [0]\n",
      "classify tree [0]\n"
     ]
    }
   ],
   "source": [
    "whether_good('sina.cn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
